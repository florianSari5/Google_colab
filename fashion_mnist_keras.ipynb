{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EuSFUMdvmCwi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/florianSari5/Google_colab/blob/master/fashion_mnist_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAElF-NellCi",
        "colab_type": "text"
      },
      "source": [
        "## Import & loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szQNUDoIcmrL",
        "colab_type": "code",
        "outputId": "30753457-f012-471e-9dcf-d46f735b086f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D,AveragePooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Concatenate\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras import Model, Input\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 9us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_NEzL-VlquS",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9r5iprjd01J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "img_rows, img_cols = 28,28\n",
        "chanDim = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn1trlGgdM47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channel_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0],1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0],1, img_rows, img_cols)\n",
        "  input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0],img_rows, img_cols,1)\n",
        "    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train =x_train.astype('float32')\n",
        "x_test =x_test.astype('float32')\n",
        "x_train/= 255\n",
        "x_test/= 255\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "datagen.fit(x_train, augment=True)\n",
        "\n",
        "\n",
        "\n",
        "print(x_train.shape[0],'train samples')\n",
        "print(x_test.shape[0],'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMB2uGOQ4KDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model with shortcut\n",
        "model_input= Input(shape=(28,28,1))\n",
        "\n",
        "x =Activation(\"relu\")(model_input)\n",
        "x =BatchNormalization(axis=chanDim)(x)\n",
        "conv1_output =Conv2D(32, (1, 1), padding=\"same\")(x)\n",
        "\n",
        "x =Activation(\"relu\")(x)\n",
        "x =BatchNormalization(axis=chanDim)(x)\n",
        "x =MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x =Dropout(0.25)(x)\n",
        "\n",
        "x =Conv2D(16, (1, 1), padding=\"same\")(x)\n",
        "x =Conv2D(16, (3, 3), padding=\"same\")(x)\n",
        "x =Activation(\"relu\")(x)\n",
        "x =BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x =MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x =Dropout(0.25)(x)\n",
        "\n",
        "z = MaxPooling2D(pool_size=(4, 4))(conv1_output)\n",
        "Concatenate()([x,z])\n",
        "\n",
        "x =Flatten()(x)\n",
        "x =Dense(200)(x)\n",
        "x =Activation(\"relu\")(x)\n",
        "x =BatchNormalization()(x)\n",
        "x =Dropout(0.5)(x)\n",
        "x =Dense(num_classes)(x)\n",
        "x =Activation(\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=[model_input], outputs=[x])\n",
        "\n",
        "model.summary()\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=sgd,metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJvuZP94cnfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec846d54-9d02-41ce-e3db-c5d6065ff7b5"
      },
      "source": [
        "#model 94,00%\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(32, (1, 1), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), padding=\"same\"))\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), padding=\"same\"))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), padding=\"same\"))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=rmsprop,metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='auto', min_delta=0.00001, cooldown=0, min_lr=0)\n",
        "modelCheckPoint = keras.callbacks.ModelCheckpoint('./model_94', monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_105 (Conv2D)          (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 28, 28, 32)        2080      \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_93 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 14, 14, 16)        528       \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_94 (Batc (None, 14, 14, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 14, 14, 16)        272       \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 14, 14, 64)        9280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_95 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_96 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_97 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 7, 7, 16)          1040      \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 7, 7, 64)          9280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_98 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 256)               147712    \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_101 (Bat (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 326,122\n",
            "Trainable params: 324,618\n",
            "Non-trainable params: 1,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcuOLjNVCLG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model 94,5%\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), padding=\"same\"))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (1, 1), padding=\"same\"))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "\n",
        "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=rmsprop,metrics=['accuracy'])\n",
        "modelCheckPoint = keras.callbacks.ModelCheckpoint('./model_94', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='auto', min_delta=0.00001, cooldown=0, min_lr=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YTWmwSLISTY",
        "colab_type": "code",
        "outputId": "b76e3619-6728-493e-8404-c5c74289cf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://0bff972b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh47Xk-qWckW",
        "colab_type": "code",
        "outputId": "bd301710-d096-4651-f623-10de5f280685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Data augmentation\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "\tvalidation_data =(x_test, y_test), steps_per_epoch=len(x_train)//batch_size,\n",
        "\tepochs=epochs, shuffle=True,callbacks=[reduce_lr, modelCheckPoint, TensorBoardColabCallback(tbc)]) \n",
        "score=model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "468/468 [==============================] - 14s 29ms/step - loss: 0.6114 - acc: 0.7840 - val_loss: 0.5221 - val_acc: 0.8255\n",
            "\n",
            "Epoch 00001: saving model to ./model_94\n",
            "Epoch 2/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.3533 - acc: 0.8718 - val_loss: 0.3283 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00002: saving model to ./model_94\n",
            "Epoch 3/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.3022 - acc: 0.8899 - val_loss: 0.3966 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00003: saving model to ./model_94\n",
            "Epoch 4/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.2770 - acc: 0.8984 - val_loss: 0.2903 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00004: saving model to ./model_94\n",
            "Epoch 5/150\n",
            "468/468 [==============================] - 12s 27ms/step - loss: 0.2621 - acc: 0.9056 - val_loss: 0.2522 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00005: saving model to ./model_94\n",
            "Epoch 6/150\n",
            "468/468 [==============================] - 13s 27ms/step - loss: 0.2447 - acc: 0.9110 - val_loss: 0.2953 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00006: saving model to ./model_94\n",
            "Epoch 7/150\n",
            "468/468 [==============================] - 13s 27ms/step - loss: 0.2316 - acc: 0.9158 - val_loss: 0.2320 - val_acc: 0.9149\n",
            "\n",
            "Epoch 00007: saving model to ./model_94\n",
            "Epoch 8/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.2232 - acc: 0.9194 - val_loss: 0.2437 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00008: saving model to ./model_94\n",
            "Epoch 9/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.2150 - acc: 0.9222 - val_loss: 0.2359 - val_acc: 0.9161\n",
            "\n",
            "Epoch 00009: saving model to ./model_94\n",
            "Epoch 10/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.2096 - acc: 0.9241 - val_loss: 0.2314 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00010: saving model to ./model_94\n",
            "Epoch 11/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.2012 - acc: 0.9271 - val_loss: 0.2161 - val_acc: 0.9218\n",
            "\n",
            "Epoch 00011: saving model to ./model_94\n",
            "Epoch 12/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1948 - acc: 0.9295 - val_loss: 0.2370 - val_acc: 0.9165\n",
            "\n",
            "Epoch 00012: saving model to ./model_94\n",
            "Epoch 13/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1917 - acc: 0.9310 - val_loss: 0.2080 - val_acc: 0.9261\n",
            "\n",
            "Epoch 00013: saving model to ./model_94\n",
            "Epoch 14/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1884 - acc: 0.9308 - val_loss: 0.1986 - val_acc: 0.9294\n",
            "\n",
            "Epoch 00014: saving model to ./model_94\n",
            "Epoch 15/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1809 - acc: 0.9343 - val_loss: 0.2557 - val_acc: 0.9078\n",
            "\n",
            "Epoch 00015: saving model to ./model_94\n",
            "Epoch 16/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1807 - acc: 0.9344 - val_loss: 0.2122 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00016: saving model to ./model_94\n",
            "Epoch 17/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1714 - acc: 0.9370 - val_loss: 0.2074 - val_acc: 0.9292\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 00017: saving model to ./model_94\n",
            "Epoch 18/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1527 - acc: 0.9442 - val_loss: 0.1895 - val_acc: 0.9320\n",
            "\n",
            "Epoch 00018: saving model to ./model_94\n",
            "Epoch 19/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1472 - acc: 0.9470 - val_loss: 0.2462 - val_acc: 0.9182\n",
            "\n",
            "Epoch 00019: saving model to ./model_94\n",
            "Epoch 20/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1444 - acc: 0.9476 - val_loss: 0.2063 - val_acc: 0.9309\n",
            "\n",
            "Epoch 00020: saving model to ./model_94\n",
            "Epoch 21/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1385 - acc: 0.9492 - val_loss: 0.2107 - val_acc: 0.9301\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 00021: saving model to ./model_94\n",
            "Epoch 22/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1281 - acc: 0.9532 - val_loss: 0.1934 - val_acc: 0.9361\n",
            "\n",
            "Epoch 00022: saving model to ./model_94\n",
            "Epoch 23/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1232 - acc: 0.9553 - val_loss: 0.1903 - val_acc: 0.9372\n",
            "\n",
            "Epoch 00023: saving model to ./model_94\n",
            "Epoch 24/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1211 - acc: 0.9556 - val_loss: 0.2032 - val_acc: 0.9348\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 00024: saving model to ./model_94\n",
            "Epoch 25/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1166 - acc: 0.9568 - val_loss: 0.1914 - val_acc: 0.9383\n",
            "\n",
            "Epoch 00025: saving model to ./model_94\n",
            "Epoch 26/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1137 - acc: 0.9583 - val_loss: 0.1940 - val_acc: 0.9385\n",
            "\n",
            "Epoch 00026: saving model to ./model_94\n",
            "Epoch 27/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1101 - acc: 0.9590 - val_loss: 0.1938 - val_acc: 0.9380\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 00027: saving model to ./model_94\n",
            "Epoch 28/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1086 - acc: 0.9598 - val_loss: 0.1921 - val_acc: 0.9387\n",
            "\n",
            "Epoch 00028: saving model to ./model_94\n",
            "Epoch 29/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1050 - acc: 0.9612 - val_loss: 0.1932 - val_acc: 0.9383\n",
            "\n",
            "Epoch 00029: saving model to ./model_94\n",
            "Epoch 30/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1054 - acc: 0.9610 - val_loss: 0.1925 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 00030: saving model to ./model_94\n",
            "Epoch 31/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1020 - acc: 0.9626 - val_loss: 0.1947 - val_acc: 0.9399\n",
            "\n",
            "Epoch 00031: saving model to ./model_94\n",
            "Epoch 32/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1029 - acc: 0.9626 - val_loss: 0.1940 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00032: saving model to ./model_94\n",
            "Epoch 33/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0998 - acc: 0.9640 - val_loss: 0.1958 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 00033: saving model to ./model_94\n",
            "Epoch 34/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1040 - acc: 0.9621 - val_loss: 0.1946 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00034: saving model to ./model_94\n",
            "Epoch 35/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1015 - acc: 0.9637 - val_loss: 0.1952 - val_acc: 0.9399\n",
            "\n",
            "Epoch 00035: saving model to ./model_94\n",
            "Epoch 36/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1007 - acc: 0.9634 - val_loss: 0.1950 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 00036: saving model to ./model_94\n",
            "Epoch 37/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1017 - acc: 0.9629 - val_loss: 0.1952 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00037: saving model to ./model_94\n",
            "Epoch 38/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1005 - acc: 0.9631 - val_loss: 0.1954 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00038: saving model to ./model_94\n",
            "Epoch 39/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1007 - acc: 0.9636 - val_loss: 0.1953 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\n",
            "Epoch 00039: saving model to ./model_94\n",
            "Epoch 40/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1003 - acc: 0.9628 - val_loss: 0.1953 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00040: saving model to ./model_94\n",
            "Epoch 41/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1005 - acc: 0.9633 - val_loss: 0.1956 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00041: saving model to ./model_94\n",
            "Epoch 42/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0995 - acc: 0.9644 - val_loss: 0.1956 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\n",
            "Epoch 00042: saving model to ./model_94\n",
            "Epoch 43/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0984 - acc: 0.9636 - val_loss: 0.1956 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00043: saving model to ./model_94\n",
            "Epoch 44/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0997 - acc: 0.9639 - val_loss: 0.1957 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00044: saving model to ./model_94\n",
            "Epoch 45/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0993 - acc: 0.9639 - val_loss: 0.1957 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\n",
            "Epoch 00045: saving model to ./model_94\n",
            "Epoch 46/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0996 - acc: 0.9634 - val_loss: 0.1954 - val_acc: 0.9409\n",
            "\n",
            "Epoch 00046: saving model to ./model_94\n",
            "Epoch 47/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1008 - acc: 0.9631 - val_loss: 0.1955 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00047: saving model to ./model_94\n",
            "Epoch 48/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1008 - acc: 0.9627 - val_loss: 0.1958 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\n",
            "Epoch 00048: saving model to ./model_94\n",
            "Epoch 49/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0997 - acc: 0.9637 - val_loss: 0.1958 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00049: saving model to ./model_94\n",
            "Epoch 50/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0988 - acc: 0.9638 - val_loss: 0.1956 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00050: saving model to ./model_94\n",
            "Epoch 51/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0978 - acc: 0.9646 - val_loss: 0.1954 - val_acc: 0.9410\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\n",
            "Epoch 00051: saving model to ./model_94\n",
            "Epoch 52/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1001 - acc: 0.9634 - val_loss: 0.1959 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00052: saving model to ./model_94\n",
            "Epoch 53/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0981 - acc: 0.9638 - val_loss: 0.1957 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00053: saving model to ./model_94\n",
            "Epoch 54/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0992 - acc: 0.9641 - val_loss: 0.1957 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "\n",
            "Epoch 00054: saving model to ./model_94\n",
            "Epoch 55/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0982 - acc: 0.9637 - val_loss: 0.1956 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00055: saving model to ./model_94\n",
            "Epoch 56/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0992 - acc: 0.9633 - val_loss: 0.1957 - val_acc: 0.9409\n",
            "\n",
            "Epoch 00056: saving model to ./model_94\n",
            "Epoch 57/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1014 - acc: 0.9630 - val_loss: 0.1957 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
            "\n",
            "Epoch 00057: saving model to ./model_94\n",
            "Epoch 58/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0978 - acc: 0.9646 - val_loss: 0.1956 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00058: saving model to ./model_94\n",
            "Epoch 59/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0977 - acc: 0.9634 - val_loss: 0.1956 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00059: saving model to ./model_94\n",
            "Epoch 60/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1016 - acc: 0.9625 - val_loss: 0.1955 - val_acc: 0.9402\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
            "\n",
            "Epoch 00060: saving model to ./model_94\n",
            "Epoch 61/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0988 - acc: 0.9641 - val_loss: 0.1954 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00061: saving model to ./model_94\n",
            "Epoch 62/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1005 - acc: 0.9636 - val_loss: 0.1957 - val_acc: 0.9406\n",
            "\n",
            "Epoch 00062: saving model to ./model_94\n",
            "Epoch 63/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0985 - acc: 0.9640 - val_loss: 0.1957 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
            "\n",
            "Epoch 00063: saving model to ./model_94\n",
            "Epoch 64/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0997 - acc: 0.9637 - val_loss: 0.1957 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00064: saving model to ./model_94\n",
            "Epoch 65/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1018 - acc: 0.9631 - val_loss: 0.1957 - val_acc: 0.9410\n",
            "\n",
            "Epoch 00065: saving model to ./model_94\n",
            "Epoch 66/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1008 - acc: 0.9626 - val_loss: 0.1957 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
            "\n",
            "Epoch 00066: saving model to ./model_94\n",
            "Epoch 67/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1010 - acc: 0.9619 - val_loss: 0.1956 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00067: saving model to ./model_94\n",
            "Epoch 68/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1017 - acc: 0.9616 - val_loss: 0.1955 - val_acc: 0.9402\n",
            "\n",
            "Epoch 00068: saving model to ./model_94\n",
            "Epoch 69/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0985 - acc: 0.9638 - val_loss: 0.1956 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
            "\n",
            "Epoch 00069: saving model to ./model_94\n",
            "Epoch 70/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1020 - acc: 0.9623 - val_loss: 0.1962 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00070: saving model to ./model_94\n",
            "Epoch 71/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0987 - acc: 0.9646 - val_loss: 0.1956 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00071: saving model to ./model_94\n",
            "Epoch 72/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1019 - acc: 0.9625 - val_loss: 0.1957 - val_acc: 0.9405\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
            "\n",
            "Epoch 00072: saving model to ./model_94\n",
            "Epoch 73/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0988 - acc: 0.9633 - val_loss: 0.1957 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00073: saving model to ./model_94\n",
            "Epoch 74/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1002 - acc: 0.9634 - val_loss: 0.1955 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00074: saving model to ./model_94\n",
            "Epoch 75/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.1022 - acc: 0.9626 - val_loss: 0.1959 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00075: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
            "\n",
            "Epoch 00075: saving model to ./model_94\n",
            "Epoch 76/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0994 - acc: 0.9645 - val_loss: 0.1954 - val_acc: 0.9409\n",
            "\n",
            "Epoch 00076: saving model to ./model_94\n",
            "Epoch 77/150\n",
            "468/468 [==============================] - 12s 26ms/step - loss: 0.0972 - acc: 0.9640 - val_loss: 0.1957 - val_acc: 0.9407\n",
            "\n",
            "Epoch 00077: saving model to ./model_94\n",
            "Epoch 78/150\n",
            " 68/468 [===>..........................] - ETA: 9s - loss: 0.0987 - acc: 0.9642"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7LWdV5Jh1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('fashion_mnist_model_.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQchiXFrVnDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "y_pred = model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuSFUMdvmCwi",
        "colab_type": "text"
      },
      "source": [
        "## Printing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjaVTykDjzXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n , i+1)\n",
        "    plt.imshow(x_test[110+i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}